{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_functional (intput):\n",
    "    \n",
    "    def __init__(self,input,act):\n",
    "        self.result = Tensor.new(input)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def dRefu (self,input):\n",
    "        result = 1-(input<0)\n",
    "        \n",
    "    def dSigmoid (self,input):\n",
    "        result = 1-torch.pow(torch.tanh(input),2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def dTanh(self,input):\n",
    "        result = 1-torch.tanh(x)*torch.tanh(x)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seqeuntial (arch_list):\n",
    "    \n",
    "    def __init__(self,input,act):\n",
    "        self.result = Tensor.new(input)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    def make_net (self,arch_list):\n",
    "        nb = len(self.arch_list)\n",
    "        \n",
    "        for i in range (nb):\n",
    "            check_name (arch_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight:\n",
    "    \"\"\"\n",
    "    Initializes the synaptic weights\n",
    "    \n",
    "    inputs:\n",
    "        layer_nb    :  the number of layer\n",
    "        dim_in      :  the input dimension of fully connected layer\n",
    "        dim_out     :  the output dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,layer_nb, dim_in, dim_out):\n",
    "        self.shape = (dim_in , dim_out)\n",
    "        self.name = layer_nb\n",
    "        self.data = Tensor (dim_in,dim_out).normal_()\n",
    "\n",
    "# it is a module in the net. it calls some specific parameter...   \n",
    "\n",
    "\n",
    "class Linear:\n",
    "    \"\"\"\n",
    "    An class that contains objects which only store layar's in/out connections dimension\n",
    "    \n",
    "    inputs:\n",
    "        dim_in      :  the input dimension of fully connected layer\n",
    "        dim_out     :  the output dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dim_in, dim_out):\n",
    "        self.input = dim_in\n",
    "        self.output = dim_out          \n",
    "\n",
    "        \n",
    "class Activation:\n",
    "    \"\"\"\n",
    "    A class that specify the needed activation with respect to the following code conversion\n",
    "        0: Relu(x)\n",
    "        1: Tanh(x)\n",
    "        2: Sigmoid(x)\n",
    "    \n",
    "    This class works as functional package of pytorch\n",
    "    \n",
    "    inputs:\n",
    "        code        :  the code for each activation (0,1,2)\n",
    "        input_tensor:  the input tensor\n",
    "        \n",
    "    returns:\n",
    "        result      :  the output of requested activation function with the same shape as input tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, code, input):\n",
    "        self.code = code\n",
    "        self.result = torch.Tensor.new(input.shape)\n",
    "    \n",
    "    def Relu (self,input):\n",
    "        result = input - (input<0);\n",
    "        \n",
    "    def Tanh (self,input): #WARNING!!!\n",
    "        result = torch.tanh(input)\n",
    "        \n",
    "    def Sigmoid (self,input):\n",
    "        result = 1.0/(1 + torch.exp(-input))\n",
    "\n",
    "    \n",
    "    def choose_activation (self, code):\n",
    "        if self.code ==0:\n",
    "            return self.Relu(input)\n",
    "        elif self.code ==1:\n",
    "            return self.Tanh(input)\n",
    "        elif self.code ==2:\n",
    "            return self.Sigmoid(input)\n",
    "        else: raise UnknownCodeForActivation\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net:\n",
    "    \"\"\"\n",
    "    The network class. It has the following methods:\n",
    "        param      :  returns the parameter which is asked for. Not the data! The object... \n",
    "                        Data is accessible through object.data method)\n",
    "        make_arch  :  makes the architecture of the network by taking a sequential list of [fc1,act1,fc2,act2,...]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self, seq):\n",
    "        self.param_list =[]\n",
    "        self.act_list = []\n",
    "        self.make_arch(seq)\n",
    "        \n",
    "    def param (layer):\n",
    "        return self.param_list[layer]\n",
    "    \n",
    "    def make_arch(self,seq):\n",
    "        seq_len = len (seq)\n",
    "        for layer in range (0,seq_len,2):\n",
    "            # we are sure that seq[layer] is a FC object -> need to know in / out\n",
    "            dim_in, dim_out = seq[layer].input , seq[layer].output \n",
    "            self.param_list.append ( Weight(layer, dim_in, dim_out) )#object (Activation / Linear) )   #... should be filled wrt seq type and inputs\n",
    "            # activation recognition\n",
    "            if seq[layer+1]=='relu':\n",
    "                self.act_list.append(0)\n",
    "            elif seq[layer+1]=='tanh':\n",
    "                self.act_list.append(1)\n",
    "            elif seq[layer+1]=='sig':\n",
    "                self.act_list.append(2)\n",
    "            else: raise UnknownActivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft, tests, and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UnknownActivation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-0185140cbc2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'regu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tanh'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-581321d4abd8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_list\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_arch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-581321d4abd8>\u001b[0m in \u001b[0;36mmake_arch\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'sig'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'UnknownActivation' is not defined"
     ]
    }
   ],
   "source": [
    "seq = [Linear(4,7),'regu',Linear(7,4),'tanh']    \n",
    "model = net (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.3474  0.0254  1.1912 -0.4338\n",
       "-0.1570  3.0292  0.7686  0.5892\n",
       "-0.1642  0.1402  1.1387 -1.0072\n",
       "-0.9680  1.3377 -1.0943 -1.2231\n",
       "-2.2461 -0.8587 -1.4203  0.5847\n",
       " 0.1913  1.0071  0.2806 -0.6999\n",
       "-0.8223  1.6559  1.7871 -0.7000\n",
       "[torch.FloatTensor of size 7x4]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.param_list[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= Tensor(3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
