{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-7-ad04dc6900f7>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-ad04dc6900f7>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    return result\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "class Activation_functional (intput):\n",
    "    \n",
    "    def __init__(self,input,act):\n",
    "        self.result = Tensor.new(input)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def dRefu (self,input):\n",
    "        result = 1-(input<0)\n",
    "        \n",
    "    def dSigmoid (self,input):\n",
    "        result = 1-torch.pow(torch.tanh(input),2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def dTanh(self,input):\n",
    "        result = 1-torch.tanh(x)*torch.tanh(x)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seqeuntial (arch_list):\n",
    "    \n",
    "    def __init__(self,input,act):\n",
    "        self.result = Tensor.new(input)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    def make_net (self,arch_list):\n",
    "        nb = len(self.arch_list)\n",
    "        \n",
    "        for i in range (nb):\n",
    "            check_name (arch_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    A class that specify the needed activation with respect to the following code conversion\\n        0: Relu(x)\\n        1: Tanh(x)\\n        2: Sigmoid(x)\\n    \\n    This class works as functional package of pytorch\\n    \\n    inputs:\\n        code        :  the code for each activation (0,1,2)\\n        input_tensor:  the input tensor\\n        \\n    returns:\\n        result      :  the output of requested activation function with the same shape as input tensor\\n    \\n    \\n    def __init__(self, code, input):\\n        self.code = code\\n        \\n        self.result = torch.Tensor.new(input.shape)\\n    \\n    def Relu (self,input):\\n        result = input - (input<0);\\n        \\n    def Tanh (self,input): #WARNING!!!\\n        result = torch.tanh(input)\\n        \\n    def Sigmoid (self,input):\\n        result = 1.0/(1 + torch.exp(-input))\\n\\n    \\n    def choose_activation (self, code,input):\\n        if self.code ==0:\\n            self.result = self.Relu(input)\\n        elif self.code ==1:\\n            self.result = self.Tanh(input)\\n        elif self.code ==2:\\n            self.result = self.Sigmoid(input)\\n        else: raise UnknownCodeForActivation\\n        return self.result \\n        '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Weight:\n",
    "    \"\"\"\n",
    "    Initializes the synaptic weights\n",
    "    \n",
    "    inputs:\n",
    "        layer_nb    :  the number of layer\n",
    "        dim_in      :  the input dimension of fully connected layer\n",
    "        dim_out     :  the output dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,layer_nb, dim_in, dim_out):\n",
    "        self.shape = (dim_in , dim_out)\n",
    "        self.name = layer_nb\n",
    "        self.data = Tensor (dim_in,dim_out).normal_()\n",
    "\n",
    "# it is a module in the net. it calls some specific parameter...   \n",
    "\n",
    "\n",
    "class Linear:\n",
    "    \"\"\"\n",
    "    An class that contains objects which only store layar's in/out connections dimension\n",
    "    \n",
    "    inputs:\n",
    "        dim_in      :  the input dimension of fully connected layer\n",
    "        dim_out     :  the output dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dim_in, dim_out):\n",
    "        self.input = dim_in\n",
    "        self.output = dim_out          \n",
    "\n",
    "        \n",
    "def Activation(code,input):\n",
    "        \n",
    "    result = torch.Tensor.new(input.shape)\n",
    "    \n",
    "    if code ==0:\n",
    "        result = input - (input<0).float()*input\n",
    "    elif code ==1:\n",
    "        result = torch.tanh(input)\n",
    "    elif code ==2:\n",
    "        result = 1.0/(1 + torch.exp(-input))\n",
    "    else: raise UnknownCodeForActivation\n",
    "    return result \n",
    "\"\"\"\n",
    "    A class that specify the needed activation with respect to the following code conversion\n",
    "        0: Relu(x)\n",
    "        1: Tanh(x)\n",
    "        2: Sigmoid(x)\n",
    "    \n",
    "    This class works as functional package of pytorch\n",
    "    \n",
    "    inputs:\n",
    "        code        :  the code for each activation (0,1,2)\n",
    "        input_tensor:  the input tensor\n",
    "        \n",
    "    returns:\n",
    "        result      :  the output of requested activation function with the same shape as input tensor\n",
    "    \n",
    "    \n",
    "    def __init__(self, code, input):\n",
    "        self.code = code\n",
    "        \n",
    "        self.result = torch.Tensor.new(input.shape)\n",
    "    \n",
    "    def Relu (self,input):\n",
    "        result = input - (input<0);\n",
    "        \n",
    "    def Tanh (self,input): #WARNING!!!\n",
    "        result = torch.tanh(input)\n",
    "        \n",
    "    def Sigmoid (self,input):\n",
    "        result = 1.0/(1 + torch.exp(-input))\n",
    "\n",
    "    \n",
    "    def choose_activation (self, code,input):\n",
    "        if self.code ==0:\n",
    "            self.result = self.Relu(input)\n",
    "        elif self.code ==1:\n",
    "            self.result = self.Tanh(input)\n",
    "        elif self.code ==2:\n",
    "            self.result = self.Sigmoid(input)\n",
    "        else: raise UnknownCodeForActivation\n",
    "        return self.result \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class net:\n",
    "    \"\"\"\n",
    "    The network class. It has the following methods:\n",
    "        param      :  returns the parameter which is asked for. Not the data! The object... \n",
    "                        Data is accessible through object.data method)\n",
    "        make_arch  :  makes the architecture of the network by taking a sequential list of [fc1,act1,fc2,act2,...]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self, seq=[]):\n",
    "        self.param_list =[]\n",
    "        self.act_list = []\n",
    "        self.make_arch(seq)\n",
    "        \n",
    "    def param (self,layer):\n",
    "        return self.param_list[layer]\n",
    "    \n",
    "    def make_arch(self,seq):\n",
    "        seq_len = len (seq)\n",
    "        for layer in range (0,seq_len,2):\n",
    "            # we are sure that seq[layer] is a FC object -> need to know in / out\n",
    "            dim_in, dim_out = seq[layer].input , seq[layer].output \n",
    "            self.param_list.append ( Weight(layer, dim_in, dim_out) )#object (Activation / Linear) )   #... should be filled wrt seq type and inputs\n",
    "            # activation recognition\n",
    "            if seq[layer+1]=='relu':\n",
    "                self.act_list.append(0)\n",
    "            elif seq[layer+1]=='tanh':\n",
    "                self.act_list.append(1)\n",
    "            elif seq[layer+1]=='sig':\n",
    "                self.act_list.append(2)\n",
    "            else: raise UnknownActivation\n",
    "                \n",
    "    def forward(self,x):\n",
    "        \n",
    "        for layer,W in enumerate(self.param_list):\n",
    "            s=x.mm(W.data)\n",
    "            x=Activation(self.act_list[layer],s)\n",
    "            print(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft, tests, and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [Linear(4,7),'relu']    \n",
    "model = net (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000  4.7655  9.7860  0.5926  0.0000  1.8284  0.0000\n",
      "[torch.FloatTensor of size 1x7]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  4.7655  9.7860  0.5926  0.0000  1.8284  0.0000\n",
       "[torch.FloatTensor of size 1x7]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(Tensor([[1.,5.,-1.,-1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=Tensor([[1,3,-5,0,-2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=(a>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  0  0  0  1\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  1  0  1  0\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a<0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
