{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-7-ad04dc6900f7>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-ad04dc6900f7>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    return result\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "class Activation_functional (intput):\n",
    "    \n",
    "    def __init__(self,input_,act):\n",
    "        self.result = Tensor.new(input_)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def dRefu (self,input_):\n",
    "        result = 1-(input_<0)\n",
    "        \n",
    "    def dSigmoid (self,input_):\n",
    "        result = 1-torch.pow(torch.tanh(input_),2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def dTanh(self,input_):\n",
    "        result = 1-torch.tanh(x)*torch.tanh(x)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seqeuntial (arch_list):\n",
    "    \n",
    "    def __init__(self,input_,act):\n",
    "        self.result = Tensor.new(input_)\n",
    "        self.kind   = act   # Relu, Sig, Relu' , sig'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_aug[index], self.train_target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "    \n",
    "    def make_net (self,arch_list):\n",
    "        nb = len(self.arch_list)\n",
    "        \n",
    "        for i in range (nb):\n",
    "            check_name (arch_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weight:\n",
    "    \"\"\"\n",
    "    Initializes the synaptic weights\n",
    "    \n",
    "    input_s:\n",
    "        layer_nb    :  the number of layer\n",
    "        dim_in      :  the input_ dimension of fully connected layer\n",
    "        dim_out     :  the output_ dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,layer_nb, dim_in, dim_out):\n",
    "        self.shape = (dim_in , dim_out)\n",
    "        self.name = layer_nb\n",
    "        self.bias = Tensor(dim_out,1).fill_(0)\n",
    "        self.data = Tensor(dim_in,dim_out).normal_()\n",
    "        \n",
    "\n",
    "# it is a module in the net. it calls some specific parameter...   \n",
    "\n",
    "\n",
    "class Linear:\n",
    "    \"\"\"\n",
    "    An class that contains objects which only store layar's in/out connections dimension\n",
    "    \n",
    "    input_s:\n",
    "        dim_in      :  the input_ dimension of fully connected layer\n",
    "        dim_out     :  the output_ dimension of fully connected layer\n",
    "        \n",
    "    returns:\n",
    "        Nothing \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dim_in, dim_out):\n",
    "        self.input_ = dim_in\n",
    "        self.output_ = dim_out          \n",
    "\n",
    "        \n",
    "def Activation(code,input_):\n",
    "        \n",
    "    result = torch.Tensor.new(input_.shape)\n",
    "    \n",
    "    if code ==0:\n",
    "        result = input_ - (input_<0).float()*input_\n",
    "    elif code ==1:\n",
    "        result = torch.tanh(input_)\n",
    "    elif code ==2:\n",
    "        result = 1.0/(1 + torch.exp(-input_))\n",
    "    else: raise UnknownCodeForActivation\n",
    "    return result \n",
    "    \"\"\"\n",
    "    A class that specify the needed activation with respect to the following code conversion\n",
    "        0: Relu(x)\n",
    "        1: Tanh(x)\n",
    "        2: Sigmoid(x)\n",
    "    \n",
    "    This class works as functional package of pytorch\n",
    "    \n",
    "    input_s:\n",
    "        code        :  the code for each activation (0,1,2)\n",
    "        input__tensor:  the input_ tensor\n",
    "        \n",
    "    returns:\n",
    "        result      :  the output_ of requested activation function with the same shape as input_ tensor\n",
    "    \n",
    "    \n",
    "    def __init__(self, code, input_):\n",
    "        self.code = code\n",
    "        \n",
    "        self.result = torch.Tensor.new(input_.shape)\n",
    "    \n",
    "    def Relu (self,input_):\n",
    "        result = input_ - (input_<0);\n",
    "        \n",
    "    def Tanh (self,input_): #WARNING!!!\n",
    "        result = torch.tanh(input_)\n",
    "        \n",
    "    def Sigmoid (self,input_):\n",
    "        result = 1.0/(1 + torch.exp(-input_))\n",
    "\n",
    "    \n",
    "    def choose_activation (self, code,input_):\n",
    "        if self.code ==0:\n",
    "            self.result = self.Relu(input_)\n",
    "        elif self.code ==1:\n",
    "            self.result = self.Tanh(input_)\n",
    "        elif self.code ==2:\n",
    "            self.result = self.Sigmoid(input_)\n",
    "        else: raise UnknownCodeForActivation\n",
    "        return self.result \n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    \"\"\"\n",
    "    The network class. It has the following methods:\n",
    "        param      :  returns the parameter which is asked for. Not the data! The object... \n",
    "                        Data is accessible through object.data method)\n",
    "        make_arch  :  makes the architecture of the network by taking a sequential list of [fc1,act1,fc2,act2,...]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seq=[]):\n",
    "        self.param_list = []\n",
    "        self.act_list = []\n",
    "        self.make_arch(seq)\n",
    "        \n",
    "    def param(self,layer):\n",
    "        return self.param_list[layer]\n",
    "    \n",
    "    def make_arch(self,seq):\n",
    "        seq_len = len (seq)\n",
    "        for layer in range (0,seq_len,2):\n",
    "            # we are sure that seq[layer] is a FC object -> need to know in / out\n",
    "            dim_in, dim_out = seq[layer].input_ , seq[layer].output_ \n",
    "            self.param_list.append ( Weight(layer, dim_in, dim_out) )#object (Activation / Linear) )   #... should be filled wrt seq type and input_s\n",
    "            # activation recognition\n",
    "            if seq[layer+1]=='relu':\n",
    "                self.act_list.append(0)\n",
    "            elif seq[layer+1]=='tanh':\n",
    "                self.act_list.append(1)\n",
    "            elif seq[layer+1]=='sig':\n",
    "                self.act_list.append(2)\n",
    "            else: raise UnknownActivation\n",
    "                \n",
    "    def forward(self,x): \n",
    "        for layer, W in enumerate(self.param_list):\n",
    "            x = x.mm(W.data) + W.bias.t()\n",
    "            x = Activation(self.act_list[layer],x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft, tests, and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq = [Linear(2,2),'tanh',Linear(2,3),'relu']    \n",
    "model = Net(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1608  0.0000  0.0000\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(Tensor([[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = model.param_list[0].data\n",
    "w2 = model.param_list[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
