{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_bci as bci\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_input size:', torch.Size([316, 28, 1, 50]))\n",
      "('train_target size:', torch.Size([316]))\n",
      "('test_input size:', torch.Size([100, 28, 1, 50]))\n",
      "('test_target size:', torch.Size([100]))\n"
     ]
    }
   ],
   "source": [
    "train_input , train_target = bci.load ( root = \"./ data_bci\")\n",
    "test_input , test_target = bci.load ( root = \"./ data_bci \" , train = False )\n",
    "\n",
    "train_target = Variable(train_target)\n",
    "train_input = Variable(train_input.unsqueeze(dim=2))\n",
    "test_input = Variable(test_input.unsqueeze(dim=2))\n",
    "test_target = Variable(test_target)\n",
    "\n",
    "mu, std = train_input.data.mean(), train_input.data.std() \n",
    "train_input.data.sub_(mu).div_(std)\n",
    "test_input.data.sub_(mu).div_(std)\n",
    "\n",
    "\n",
    "print('train_input size:' , train_input.size())\n",
    "print ( 'train_target size:' , train_target.size())\n",
    "print ('test_input size:' , test_input.size())\n",
    "print ('test_target size:' , test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function computes the accuracy\n",
    "def accuracy(output,target):\n",
    "    return (output.float()==target.float()).float().sum()/len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0_conv1=28\n",
    "dim1_conv1=32\n",
    "dim0_conv2=dim1_conv1\n",
    "dim1_conv2= 40\n",
    "\n",
    "fc1_dim0 =  1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d (28, 32, kernel_size = (1,5))    # after conv: 20*32*1*46\n",
    "        self.avg_pool1 = nn.AvgPool2d(kernel_size = (1,4))      # size -> 1/4 *size\n",
    "        self.conv2 = nn.Conv2d (32 , 64, kernel_size = (1,5))   \n",
    "        self.fc1 = nn.Linear (448 , 50)                         # size : 64 ->32 => 448/2\n",
    "        self.fc2 = nn.Linear (50 , 2)\n",
    "        \n",
    "    def forward (self , x):\n",
    "        x = self.conv1(x)\n",
    "        #print ('after first conv',x.size())\n",
    "        x = F.relu(self.avg_pool1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view (-1, 448)\n",
    "        x = F.relu ( self.fc1 (x))\n",
    "        x = self.fc2(x)\n",
    "                   #x = F.relu(F.max_pool2d(self.conv1(x), kernel_size = 3, stride =3) )\n",
    "        #x = F.relu (F.max_pool2d ( self.conv2(x), kernel_size =2, stride =2) )\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'loss train:', 0.036786358803510666, 'loss test:', 1.1606009006500244, ' accuracy test:', 0.800000011920929)\n",
      "(1, 'loss train:', 0.02580004185438156, 'loss test:', 1.195967674255371, ' accuracy test:', 0.800000011920929)\n",
      "(2, 'loss train:', 0.011333034373819828, 'loss test:', 1.2445627450942993, ' accuracy test:', 0.7900000214576721)\n",
      "(3, 'loss train:', 0.005387601908296347, 'loss test:', 1.294737696647644, ' accuracy test:', 0.7799999713897705)\n",
      "(4, 'loss train:', 0.0035095438361167908, 'loss test:', 1.3306933641433716, ' accuracy test:', 0.7900000214576721)\n",
      "(5, 'loss train:', 0.0026846681721508503, 'loss test:', 1.3568470478057861, ' accuracy test:', 0.7799999713897705)\n",
      "(6, 'loss train:', 0.0022211067844182253, 'loss test:', 1.377345323562622, ' accuracy test:', 0.7799999713897705)\n",
      "(7, 'loss train:', 0.0019191540777683258, 'loss test:', 1.3959357738494873, ' accuracy test:', 0.7799999713897705)\n",
      "(8, 'loss train:', 0.0016949467826634645, 'loss test:', 1.4131555557250977, ' accuracy test:', 0.7799999713897705)\n",
      "(9, 'loss train:', 0.0015209914417937398, 'loss test:', 1.4290831089019775, ' accuracy test:', 0.7799999713897705)\n"
     ]
    }
   ],
   "source": [
    "### train the model\n",
    "epoch = 1000\n",
    "batch_size = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.001,momentum = 0.5)\n",
    "i = 0\n",
    "for e in range(epoch):\n",
    "    for b in range(0,train_input.size(0),batch_size):\n",
    "        input_ = train_input.narrow(0,b,min(batch_size,train_input.size(0)-b))\n",
    "        target = train_target.narrow(0,b,min(batch_size,train_input.size(0)-b))\n",
    "        output = net(input_).view(min(batch_size,train_input.size(0)-b),2)\n",
    "        loss = criterion(output,target)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if e%100 == 0: # print the loss every 10 epochs\n",
    "        output = net(test_input).view(-1,2)\n",
    "        a,predicted_class = output.max(dim=1)\n",
    "        output_train = net(train_input).view(-1,2)\n",
    "        a,predicted_class_train = output.max(dim=1)\n",
    "        \n",
    "        #predicted_class = 1*(predicted_class.float().mean(dim=1) > 0.5)\n",
    "        print(e//100,'loss train:',criterion(output_train,train_target).data[0],'loss test:',criterion(output,test_target).data[0],' accuracy test:',accuracy(predicted_class,test_target).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.LongTensor(3).random_(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
