{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlc_bci as bci\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input size: torch.Size([316, 28, 1, 50])\n",
      "train_target size: torch.Size([316])\n",
      "test_input size: torch.Size([100, 28, 1, 50])\n",
      "test_target size: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_input , train_target = bci.load ( root = \"./ data_bci\")\n",
    "test_input , test_target = bci.load ( root = \"./ data_bci \" , train = False )\n",
    "\n",
    "train_target = Variable(train_target)\n",
    "train_input = Variable(train_input.unsqueeze(dim=2))\n",
    "test_input = Variable(test_input.unsqueeze(dim=2))\n",
    "test_target = Variable(test_target)\n",
    "\n",
    "mu, std = train_input.data.mean(), train_input.data.std() \n",
    "train_input.data.sub_(mu).div_(std)\n",
    "test_input.data.sub_(mu).div_(std)\n",
    "\n",
    "\n",
    "print('train_input size:' , train_input.size())\n",
    "print ( 'train_target size:' , train_target.size())\n",
    "print ('test_input size:' , test_input.size())\n",
    "print ('test_target size:' , test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function computes the accuracy\n",
    "def accuracy(output,target):\n",
    "    return (output.float()==target.float()).float().sum()/len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d (28, 32, kernel_size = (1,5))\n",
    "        self.avg_pool1 = nn.AvgPool2d(kernel_size = (1,4))\n",
    "        self.conv2 = nn.Conv2d (32 , 64, kernel_size = (1,5))\n",
    "        self.fc1 = nn.Linear (448 , 200)\n",
    "        self.fc2 = nn.Linear (200 , 2)\n",
    "        \n",
    "    def forward (self , x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.avg_pool1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view (-1, 448)\n",
    "        x = F.relu ( self.fc1 (x))\n",
    "        x = self.fc2(x)\n",
    "                   #x = F.relu(F.max_pool2d(self.conv1(x), kernel_size = 3, stride =3) )\n",
    "        #x = F.relu (F.max_pool2d ( self.conv2(x), kernel_size =2, stride =2) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss train:  0.6936008930206299 loss test 0.6927070021629333  accuracy test  0.4699999988079071\n",
      "1 loss train:  0.6863560676574707 loss test 0.6956783533096313  accuracy test  0.4699999988079071\n",
      "2 loss train:  0.6719890832901001 loss test 0.7013039588928223  accuracy test  0.41999998688697815\n",
      "3 loss train:  0.6429463624954224 loss test 0.7169969081878662  accuracy test  0.4399999976158142\n",
      "4 loss train:  0.5761215686798096 loss test 0.6860684156417847  accuracy test  0.5400000214576721\n",
      "5 loss train:  0.4948302209377289 loss test 0.6379230618476868  accuracy test  0.6399999856948853\n",
      "6 loss train:  0.4354327619075775 loss test 0.6297763586044312  accuracy test  0.6399999856948853\n",
      "7 loss train:  0.3722091615200043 loss test 0.6171790957450867  accuracy test  0.6800000071525574\n",
      "8 loss train:  0.3147490918636322 loss test 0.6212679743766785  accuracy test  0.699999988079071\n",
      "9 loss train:  0.2581411302089691 loss test 0.6359745860099792  accuracy test  0.7300000190734863\n"
     ]
    }
   ],
   "source": [
    "### train the model\n",
    "epoch = 1000\n",
    "batch_size = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.001,momentum = 0.5)\n",
    "i = 0\n",
    "for e in range(epoch):\n",
    "    for b in range(0,train_input.size(0),batch_size):\n",
    "        input_ = train_input.narrow(0,b,min(batch_size,train_input.size(0)-b))\n",
    "        target = train_target.narrow(0,b,min(batch_size,train_input.size(0)-b))\n",
    "        output = net(input_).view(min(batch_size,train_input.size(0)-b),2)\n",
    "        loss = criterion(output,target)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if e%100 == 0: # print the loss every 10 epochs\n",
    "        output = net(test_input).view(-1,2)\n",
    "        a,predicted_class = output.max(dim=1)\n",
    "        output_train = net(train_input).view(-1,2)\n",
    "        a,predicted_class_train = output.max(dim=1)\n",
    "        \n",
    "        #predicted_class = 1*(predicted_class.float().mean(dim=1) > 0.5)\n",
    "        print(e//100,'loss train:',criterion(output_train,train_target).data[0],'loss test:',criterion(output,test_target).data[0],' accuracy test:',accuracy(predicted_class,test_target).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.LongTensor(3).random_(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
